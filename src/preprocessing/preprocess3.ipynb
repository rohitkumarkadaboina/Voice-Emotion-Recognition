{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPqAcC3GMy+ZtTtfE9RM40V"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip show resampy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LVapEjYFbTNE","executionInfo":{"status":"ok","timestamp":1753497644916,"user_tz":-330,"elapsed":1713,"user":{"displayName":"Rohit","userId":"16299795322008559840"}},"outputId":"fcefdb68-c7fe-4edc-a5b7-7f85bfa39802"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: resampy\n","Version: 0.4.3\n","Summary: Efficient signal resampling\n","Home-page: https://github.com/bmcfee/resampy\n","Author: Brian McFee\n","Author-email: brian.mcfee@nyu.edu\n","License: ISC\n","Location: /usr/local/lib/python3.11/dist-packages\n","Requires: numba, numpy\n","Required-by: \n"]}]},{"cell_type":"code","source":["!pip install pyrubberband"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lJgxtAE9e_yE","executionInfo":{"status":"ok","timestamp":1753497651468,"user_tz":-330,"elapsed":6550,"user":{"displayName":"Rohit","userId":"16299795322008559840"}},"outputId":"ff424e44-5638-4740-c4fd-26dda5ff9775"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyrubberband in /usr/local/lib/python3.11/dist-packages (0.4.0)\n","Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from pyrubberband) (2.0.2)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyrubberband) (0.13.1)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->pyrubberband) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyrubberband) (2.22)\n"]}]},{"cell_type":"code","source":["!apt-get install -y rubberband-cli\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aRhG7WfpfExh","executionInfo":{"status":"ok","timestamp":1753497656703,"user_tz":-330,"elapsed":5232,"user":{"displayName":"Rohit","userId":"16299795322008559840"}},"outputId":"a56a211e-3dc3-40e2-8dd7-18f129c358e2"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","rubberband-cli is already the newest version (2.0.0-2).\n","0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"]}]},{"cell_type":"code","source":["!pip install resampy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1MUekgU1bDNz","executionInfo":{"status":"ok","timestamp":1753497668468,"user_tz":-330,"elapsed":11763,"user":{"displayName":"Rohit","userId":"16299795322008559840"}},"outputId":"f57e6259-0f61-4222-f9da-72ddc78374c8"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: resampy in /usr/local/lib/python3.11/dist-packages (0.4.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from resampy) (2.0.2)\n","Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.11/dist-packages (from resampy) (0.60.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.53->resampy) (0.43.0)\n"]}]},{"cell_type":"code","execution_count":33,"metadata":{"id":"4ObhyKQ_hBTF","executionInfo":{"status":"ok","timestamp":1753497668489,"user_tz":-330,"elapsed":18,"user":{"displayName":"Rohit","userId":"16299795322008559840"}}},"outputs":[],"source":["# ðŸ“ preprocess.ipynb - Updated with Delta + Delta-Delta Features\n","\n","## 1. Import Libraries\n","\n","import os\n","import numpy as np\n","import librosa\n","import librosa.display\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import joblib\n","from tqdm import tqdm\n","\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v7rhoco7ivsK","executionInfo":{"status":"ok","timestamp":1753497670186,"user_tz":-330,"elapsed":1694,"user":{"displayName":"Rohit","userId":"16299795322008559840"}},"outputId":"524f54a4-e820-4f27-b8b0-697c8b5b66e1"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["os.getcwd()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"8xFZ7FTNUbEK","executionInfo":{"status":"ok","timestamp":1753497670281,"user_tz":-330,"elapsed":61,"user":{"displayName":"Rohit","userId":"16299795322008559840"}},"outputId":"4fb680d4-c0f4-4c5c-b3df-c3c166fa3509"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["# import kagglehub\n","\n","# # Download latest version\n","# path = kagglehub.dataset_download(\"uwrfkaggler/ravdess-emotional-speech-audio\")\n","\n","# print(\"Path to dataset files:\", path)"],"metadata":{"id":"8ZH0BDJEh6P4","executionInfo":{"status":"ok","timestamp":1753497670338,"user_tz":-330,"elapsed":4,"user":{"displayName":"Rohit","userId":"16299795322008559840"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["# import os\n","# import shutil\n","\n","# # Source: Kaggle dataset location (read-only)\n","# kaggle_dataset_path = \"/kaggle/input/ravdess-emotional-speech-audio\"\n","\n","# # Destination: Your project folder in Google Drive\n","# target_path = \"/content/drive/MyDrive/Colab Notebooks/voice_emotion_recognition/data/raw/ravdess\"\n","\n","# # Make sure destination exists\n","# os.makedirs(target_path, exist_ok=True)\n","\n","# # Loop over actor folders and copy them\n","# for folder in os.listdir(kaggle_dataset_path):\n","#     src = os.path.join(kaggle_dataset_path, folder)\n","#     dest = os.path.join(target_path, folder)\n","#     if os.path.isdir(src):\n","#         shutil.copytree(src, dest, dirs_exist_ok=True)\n","#         print(f\"âœ… Copied: {folder}\")\n","\n","# print(\"ðŸŽ‰ All Actor folders copied to:\", target_path)\n"],"metadata":{"id":"lwGSRT8Nitxz","executionInfo":{"status":"ok","timestamp":1753497670346,"user_tz":-330,"elapsed":4,"user":{"displayName":"Rohit","userId":"16299795322008559840"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["os.listdir(\"/content/drive/MyDrive/Colab Notebooks/voice_emotion_recognition/data/raw/ravdess\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZDTdgz4Cko2k","executionInfo":{"status":"ok","timestamp":1753497670377,"user_tz":-330,"elapsed":29,"user":{"displayName":"Rohit","userId":"16299795322008559840"}},"outputId":"db7ac81e-c25c-453c-d73a-a42c7cad5c60"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Actor_12',\n"," 'Actor_16',\n"," 'Actor_17',\n"," 'Actor_04',\n"," 'Actor_07',\n"," 'Actor_13',\n"," 'Actor_06',\n"," 'Actor_15',\n"," 'Actor_08',\n"," 'Actor_05',\n"," 'Actor_09',\n"," 'Actor_01',\n"," 'Actor_11',\n"," 'Actor_10',\n"," 'Actor_02',\n"," 'Actor_23',\n"," 'Actor_18',\n"," 'Actor_14',\n"," 'Actor_19',\n"," 'Actor_21',\n"," 'Actor_03',\n"," 'Actor_20',\n"," 'Actor_22',\n"," 'Actor_24']"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":[],"metadata":{"id":"MkrjxovtoE_X","executionInfo":{"status":"ok","timestamp":1753497670380,"user_tz":-330,"elapsed":1,"user":{"displayName":"Rohit","userId":"16299795322008559840"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/voice_emotion_recognition')\n","\n","# You're telling Python:\n","# â€œTreat /content/drive/MyDrive/Colab Notebooks/voice_emotion_recognition/ as if itâ€™s the root of my codebase.\n","# So anything inside that â€” like utils/, models/, src/ â€” can now be imported easily.â€\n"],"metadata":{"id":"wdKRQdkoTA1Q","executionInfo":{"status":"ok","timestamp":1753497670383,"user_tz":-330,"elapsed":1,"user":{"displayName":"Rohit","userId":"16299795322008559840"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["os.getcwd()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"Le0WN7fIU4a_","executionInfo":{"status":"ok","timestamp":1753497670395,"user_tz":-330,"elapsed":10,"user":{"displayName":"Rohit","userId":"16299795322008559840"}},"outputId":"17388353-3263-49c5-854d-7c26871740ed"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["from src.utils.augment import apply_augmentation_pipeline"],"metadata":{"id":"fnCjO9Gbn6pS","executionInfo":{"status":"ok","timestamp":1753497670399,"user_tz":-330,"elapsed":2,"user":{"displayName":"Rohit","userId":"16299795322008559840"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["\n","\n","# ## 2. Feature Extraction Function (Log-Mel + Delta + Delta-Delta)\n","\n","# def extract_logmel(audio, sr, n_mels=128, max_len=173):\n","#     mel = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels)\n","#     logmel = librosa.power_to_db(mel, ref=np.max)\n","\n","#     # Delta and Delta-Delta\n","#     delta = librosa.feature.delta(logmel)\n","#     delta2 = librosa.feature.delta(logmel, order=2)\n","\n","#     # Stack them as 3 channels: [static, delta, delta-delta]\n","#     logmel_stack = np.stack([logmel, delta, delta2], axis=0)  # (3, n_mels, time)\n","#     logmel_stack = librosa.util.fix_length(logmel_stack, size=max_len, axis=2)\n","\n","#     # Normalize each channel independently\n","#     for i in range(3):\n","#         _min = logmel_stack[i].min()\n","#         _max = logmel_stack[i].max()\n","#         logmel_stack[i] = (logmel_stack[i] - _min) / (_max - _min + 1e-6)\n","\n","#     return logmel_stack  # shape: (3, 128, time)\n"],"metadata":{"id":"5bLZLgAMhHEZ","executionInfo":{"status":"ok","timestamp":1753497670405,"user_tz":-330,"elapsed":3,"user":{"displayName":"Rohit","userId":"16299795322008559840"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["!ls \"/content/drive/MyDrive/Colab Notebooks/voice_emotion_recognition/data/raw/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R2lThhMZWgv9","executionInfo":{"status":"ok","timestamp":1753497670452,"user_tz":-330,"elapsed":44,"user":{"displayName":"Rohit","userId":"16299795322008559840"}},"outputId":"4a37bb26-5be2-4459-f541-edb28430fb11"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["ravdess\n"]}]},{"cell_type":"code","source":["!ls \"/content/drive/MyDrive/Colab Notebooks/voice_emotion_recognition/data/raw/ravdess\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UYjYCUvDWjZ9","executionInfo":{"status":"ok","timestamp":1753497670556,"user_tz":-330,"elapsed":102,"user":{"displayName":"Rohit","userId":"16299795322008559840"}},"outputId":"3cb437e1-b6ea-44e1-bd1b-744677164824"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Actor_01  Actor_04  Actor_07  Actor_10\tActor_13  Actor_16  Actor_19  Actor_22\n","Actor_02  Actor_05  Actor_08  Actor_11\tActor_14  Actor_17  Actor_20  Actor_23\n","Actor_03  Actor_06  Actor_09  Actor_12\tActor_15  Actor_18  Actor_21  Actor_24\n"]}]},{"cell_type":"code","source":["\n","\n","## 3. Load & Preprocess RAVDESS Audio Dataset\n","DATA_PATH = \"/content/drive/MyDrive/Colab Notebooks/voice_emotion_recognition/data/raw/ravdess/\"\n","\n","os.listdir(DATA_PATH)\n","# emotion_dict = {'neutral': 0, 'calm': 1, 'happy': 2, 'sad': 3, 'angry': 4, 'fearful': 5, 'disgust': 6, 'surprised': 7}\n"],"metadata":{"id":"ily8ax05hVCd","executionInfo":{"status":"ok","timestamp":1753497670574,"user_tz":-330,"elapsed":26,"user":{"displayName":"Rohit","userId":"16299795322008559840"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8ee83c6c-e847-4371-e2dd-b80c0faa8e6c"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Actor_12',\n"," 'Actor_16',\n"," 'Actor_17',\n"," 'Actor_04',\n"," 'Actor_07',\n"," 'Actor_13',\n"," 'Actor_06',\n"," 'Actor_15',\n"," 'Actor_08',\n"," 'Actor_05',\n"," 'Actor_09',\n"," 'Actor_01',\n"," 'Actor_11',\n"," 'Actor_10',\n"," 'Actor_02',\n"," 'Actor_23',\n"," 'Actor_18',\n"," 'Actor_14',\n"," 'Actor_19',\n"," 'Actor_21',\n"," 'Actor_03',\n"," 'Actor_20',\n"," 'Actor_22',\n"," 'Actor_24']"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["# Extract emotion label from RAVDESS filename\n","def extract_emotion(filename):\n","    emotion_map = {\n","        '01': 'neutral',\n","        '02': 'calm',\n","        '03': 'happy',\n","        '04': 'sad',\n","        '05': 'angry',\n","        '06': 'fearful',\n","        '07': 'disgust',\n","        '08': 'surprised'\n","    }\n","    parts = filename.split('-')\n","    if len(parts) > 2:\n","        emotion_id = parts[2]\n","        return emotion_map.get(emotion_id, None)\n","    return None\n"],"metadata":{"id":"U7gBdwsohUPZ","executionInfo":{"status":"ok","timestamp":1753497670579,"user_tz":-330,"elapsed":3,"user":{"displayName":"Rohit","userId":"16299795322008559840"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["# Scan dataset and get list of (path, label)\n","file_label_pairs = []\n","for root, _, files in os.walk(DATA_PATH):\n","    for file in files:\n","        if file.endswith('.wav'):\n","            emotion = extract_emotion(file)\n","            if emotion:\n","                file_label_pairs.append((os.path.join(root, file), emotion))\n","\n","print(f\"Total files with valid emotion: {len(file_label_pairs)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VUczz5vpYmvT","executionInfo":{"status":"ok","timestamp":1753497670589,"user_tz":-330,"elapsed":9,"user":{"displayName":"Rohit","userId":"16299795322008559840"}},"outputId":"5118adc5-e92d-4f08-c929-7f3a59b8fbad"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Total files with valid emotion: 1440\n"]}]},{"cell_type":"code","source":["# Encode string labels into integers\n","labels = [label for _, label in file_label_pairs]\n","label_encoder = LabelEncoder()\n","y = label_encoder.fit_transform(labels)\n","\n","# Save label encoder\n","joblib.dump(label_encoder, 'label_encoder.joblib')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V2fRgBXkY1kd","executionInfo":{"status":"ok","timestamp":1753497670622,"user_tz":-330,"elapsed":32,"user":{"displayName":"Rohit","userId":"16299795322008559840"}},"outputId":"71179b8b-5901-4bc7-ffc5-aa2f083f5b73"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['label_encoder.joblib']"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["X = []\n","y = []\n","\n","# Iterate through each actor's folder\n","for actor_folder in tqdm(sorted(os.listdir(DATA_PATH)), desc=\"Processing Actors\"):\n","    actor_path = os.path.join(DATA_PATH, actor_folder)\n","\n","    if not os.path.isdir(actor_path):\n","        continue\n","\n","    # Process each audio file in the actor folder\n","    for file in os.listdir(actor_path):\n","        if not file.endswith(\".wav\"):\n","            continue\n","\n","        audio_path = os.path.join(actor_path, file)\n","\n","        try:\n","            features = apply_augmentation_pipeline(audio_path)\n","            if features is not None:\n","                X.append(features)\n","                y.append(extract_emotion(file))\n","        except Exception as e:\n","            print(f\"Error processing {file}: {e}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cJYkIXDOauRO","executionInfo":{"status":"ok","timestamp":1753497846271,"user_tz":-330,"elapsed":175646,"user":{"displayName":"Rohit","userId":"16299795322008559840"}},"outputId":"15abd15b-60fc-4576-9af0-f05c74f33a8e"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing Actors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [02:55<00:00,  7.32s/it]\n"]}]},{"cell_type":"code","source":["\n","X = np.array(X)  # shape: (samples, 3, 128, 173)\n","y = np.array(y)\n","print(\"X shape:\", X.shape)\n","print(\"y shape:\", y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lKUMXitKhPEk","executionInfo":{"status":"ok","timestamp":1753497846451,"user_tz":-330,"elapsed":169,"user":{"displayName":"Rohit","userId":"16299795322008559840"}},"outputId":"76be00da-498c-46e9-81ed-4e0f865c14b5"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["X shape: (1440, 3, 128, 173)\n","y shape: (1440,)\n"]}]},{"cell_type":"code","source":["# âœ… Final Input Shape (for Conv1D):\n","\n","# (samples, time_steps=173, features=128 Ã— 3 = 384)\n","# So letâ€™s flatten the channel and mel axis (3 Ã— 128 = 384) and keep time (173) as sequence steps."],"metadata":{"id":"uZl_46m1kXqo","executionInfo":{"status":"ok","timestamp":1753497846464,"user_tz":-330,"elapsed":18,"user":{"displayName":"Rohit","userId":"16299795322008559840"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["# X_reshaped = X.transpose(0, 3, 1, 2).reshape(X.shape[0], 173, 384)\n","# print(\"Reshaped X shape:\", X_reshaped.shape)\n","# # Explanation:\n","\n","# # .transpose(0, 3, 1, 2) â†’ makes shape (samples, time=173, channels=3, mel=128)\n","\n","# # Then reshape into (samples, 173, 384) to merge channels * mel_bins per timestep."],"metadata":{"id":"pDmGsCcxkL-u","executionInfo":{"status":"ok","timestamp":1753497846469,"user_tz":-330,"elapsed":3,"user":{"displayName":"Rohit","userId":"16299795322008559840"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["# X = X_reshaped\n","# print(\"Final X shape:\", X.shape)"],"metadata":{"id":"59Byt_YtklbO","executionInfo":{"status":"ok","timestamp":1753497846484,"user_tz":-330,"elapsed":12,"user":{"displayName":"Rohit","userId":"16299795322008559840"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["\n","## 6. Save Processed Data\n","\n","np.save(\"/content/drive/MyDrive/Colab Notebooks/voice_emotion_recognition/data/features/features_v6.npy\", X)\n","np.save(\"/content/drive/MyDrive/Colab Notebooks/voice_emotion_recognition/data/features/labels_v6.npy\", y)\n","\n"],"metadata":{"id":"d4OWUlrGhKyY","executionInfo":{"status":"ok","timestamp":1753497849402,"user_tz":-330,"elapsed":2913,"user":{"displayName":"Rohit","userId":"16299795322008559840"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["!ls \"/content/drive/MyDrive/Colab Notebooks/voice_emotion_recognition/data/features/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lZYPlX-6hxdx","executionInfo":{"status":"ok","timestamp":1753497849526,"user_tz":-330,"elapsed":121,"user":{"displayName":"Rohit","userId":"16299795322008559840"}},"outputId":"8647edcb-8606-4918-aeff-395703d95eab"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["features.npy\t features_v5.npy  labels.npy\t labels_v5.npy\n","features_v4.npy  features_v6.npy  labels_v4.npy  labels_v6.npy\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"po_T74JUhzgU"},"execution_count":null,"outputs":[]}]}